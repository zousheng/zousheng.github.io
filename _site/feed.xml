<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.5.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2017-08-11T08:59:40+08:00</updated><id>http://localhost:4000/</id><title type="html">加油的Tech Blog</title><subtitle>一个进入IT行业7年之久的IT从业者，第一年做java二次开发，第二年被Linux所吸引，转为linux Admin, 再之后到了互联网时代，也转型到了互联网运维，从事云计算和各种分布式组件。现在又到了AI和以数据驱动的时代，希望能跟上技术更新的步伐，不断提高个人技能.....
</subtitle><entry><title type="html">Mesos task cpu &amp;amp; mem setting</title><link href="http://localhost:4000/mesos-task-cpu-mem-setting/" rel="alternate" type="text/html" title="Mesos task cpu &amp; mem setting" /><published>2017-08-11T00:00:00+08:00</published><updated>2017-08-11T00:00:00+08:00</updated><id>http://localhost:4000/mesos-task-cpu-mem-setting</id><content type="html" xml:base="http://localhost:4000/mesos-task-cpu-mem-setting/">&lt;!--excerpt--&gt;

&lt;h1 id=&quot;mesos-task-cpu--mem-setting&quot;&gt;##Mesos task cpu &amp;amp; mem setting&lt;/h1&gt;

&lt;p&gt;###Runtime Isolators&lt;/p&gt;

&lt;p&gt;These isolators are used to ensure that a task behaves well at runtime and also provide runtime usage metrics for the given resource.&lt;/p&gt;

&lt;p&gt;####posix/cpu&lt;/p&gt;

&lt;p&gt;No actual resource isolation but does support returning usage metrics.&lt;/p&gt;

&lt;p&gt;Metrics: cpu user time &amp;amp; system time See: https://github.com/apache/mesos/blob/037a346a205ad7bdba99d771855f8caeea835d4a/src/usage/usage.cpp#L35&lt;/p&gt;

&lt;p&gt;####posix/mem&lt;/p&gt;

&lt;p&gt;No actual resource isolation but does support returning usage metrics.&lt;/p&gt;

&lt;p&gt;Metrics: mem_rss_bytes See: https://github.com/apache/mesos/blob/037a346a205ad7bdba99d771855f8caeea835d4a/src/usage/usage.cpp#L35&lt;/p&gt;

&lt;p&gt;####posix/disk&lt;/p&gt;

&lt;p&gt;Uses du -k -s to ensure tasks stay within disk usage limits.&lt;/p&gt;

&lt;p&gt;####Can Kill Tasks? Yes&lt;/p&gt;

&lt;p&gt;Metrics: disk_limit_bytes, disk_used_bytes&lt;/p&gt;

&lt;p&gt;// This isolator monitors the disk usage for containers, and reports
// ContainerLimitation when a container exceeds its disk quota. This
// leverages the DiskUsageCollector to ensure that we don’t induce too
// much CPU usage and disk caching effects from running ‘du’ too
// often.
####disk/du&lt;/p&gt;

&lt;p&gt;Alias for posix/disk&lt;/p&gt;

&lt;p&gt;####Can Kill Tasks? Yes&lt;/p&gt;

&lt;p&gt;####&lt;strong&gt;marathon cpu:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Marathon’s cpu setting is both a relative weight for scheduling all Docker containers across all of the Mesos slave’s CPUs and an amount of the Mesos slave’s available CPU capacity to use up&lt;/li&gt;
  &lt;li&gt;A process running in a Docker container on a Mesos slave thinks it has the same number of CPUs as the underlying machine&lt;/li&gt;
  &lt;li&gt;The OS should give relative weight to the Docker containers running on a Mesos slave according to their cpus values&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;###CPU Allocation&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;There are several flags that influence the way how Mesos limits resources. For CPU is most important isolation (we’re talking about mesos-slave/mesos-agent settings):&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;–isolation=posix/cpu,posix/mem None CPU limiting is applied mesos-executor is just a process that runs other process. You can use nice, e.g. nice -20 (for highest priority) or cpulimit commands to influence kernel planning, but Mesos’s e.g. cpu=0.1 won’t be taken into consideration.&lt;/li&gt;
  &lt;li&gt;–isolation=cgroups/cpu,cgroups/mem cgroups (part of Linux Kernel since 2.6.29) allows limiting resources used by each process or group of processes. Some distributions does not enable memory limiting by default and cgroup_enable=memory need to be passed to the kernel. But let’s focus on CPU. By default cgroups takes conservative approach where cpu=1.0 means that at least one CPU core will be reserved for the task. But in case that there is no other task running on the host it can consume all of the CPUs. Assuming that we have a host with 12 CPUs and there are two tasks running with cpu=2.0. Then each task might get up to 6 CPUs cores! (assuming no other Mesos task is running on that host). This is very dangerous, when cluster is at low load all tasks will look fine, but once there are many tasks performance of some hosts will decrease.
    &lt;ul&gt;
      &lt;li&gt;–cgroups_enable_cfs CFS stands for Completely Fair Scheduler which takes more strict approach. By default it is turned off, also not all distributions support this (you can use e.g. Docker’s check-script.sh to verify support on your system). CFS will guarantee that each process can use at most the portion specified (e.g. cpu=2.5). This comes at a cost that no other process can utilize reserved cores when some task is idle. So, make sure you’ll define your requirement well.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;####总结:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mesos默认isolation使用的是 posix/cpu,posix/mem, 这个配置只适合开发环境用，生产环境不适合，因为它没有对资源做任何的限制。(生产环境应该使用 cgroups/cpu,cgroups/mem.) &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mesos isolation 配置 cgroups/cpu,cgroups/mem , cpu使用的方式是cpu shared,这种方式对cpu没有严格限制，机器上的任何task都可以访问机器上所有cpu资源; cgroups/mem对内存限制严格，如果超过配置的数值，会调用oom-killer 销毁整个容器， 相当于kill -9 杀掉进程。 生产环境要合理配置&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mesos isolation 配置 cgroups/cpu,cgroups/mem 同时配置 CFS，这个相当于配置了独占cpu, 如果cpus 配置了1， 那么这个容器的cpu使用率就不会超过100%. 相当于一个hard limit. k8s 和 DC/OS 都是使用的这种资源隔离方式。 当服务要用到的 cpu 时间片大于设定的阈值时，服务性能会受到影响， 吞吐量会下降， 但是不会被 kill&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;marathon 上配置的 cpus 数值，不仅是一个cpu的数值，同时也可以指cpu资源的相对权重值&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;调优&quot;&gt;调优&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;沙箱所有服务的marathon上的 CPUS 改为 0.1, 沙箱的mesos slave 整体 cpu 使用率很低，在15%左右， 所以这个数值没有问题，可以提高资源利用率&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;针对私有部署中的服务 marathon CPUS可以调低 0.1， 个别 cpu 密集型的服务 e.g. webapp, gateway 可以改为0.2 或者0.3，这样总的 cpu 核数会降低很多&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;针对线上服务的 marathon CPUS 值适当调低， 线上的 mesos slave CPU 使用率一般在 30% ～ 40% 之间，使用率其实不高， 调整后整体资源使用率会更合理&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Reference:&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;https://gist.github.com/chetan/9c519c68549b55d71709cb8cc62206ae&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;https://zcox.wordpress.com/2014/09/17/cpu-resources-in-docker-mesos-and-marathon/&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="mesos" /><category term="isolation" /><summary type="html"></summary></entry><entry><title type="html">重新认识 Docker、Kubernetes 和 Apache Mesos</title><link href="http://localhost:4000/docker-vs-kubernetes-vs-apache-mesos.html" rel="alternate" type="text/html" title="重新认识 Docker、Kubernetes 和 Apache Mesos" /><published>2017-07-31T00:00:00+08:00</published><updated>2017-07-31T00:00:00+08:00</updated><id>http://localhost:4000/docker-vs-kubernetes-vs-apache-mesos</id><content type="html" xml:base="http://localhost:4000/docker-vs-kubernetes-vs-apache-mesos.html">&lt;p&gt;有无数的文章、讨论和社交网络上的交流在比较 Docker、Kubernetes 和 Mesos。
如果只听取部分信息，你会以为这三个开源项目正在为容器世界的霸权而决战。
你也可能相信选择其一几乎是一个宗教选择；真正的信徒维护他们的信仰，烧死胆敢考虑其它替代品的异端者。&lt;/p&gt;

&lt;p&gt;这都是呓语。&lt;/p&gt;

&lt;p&gt;虽然三种技术都让利用容器进行部署、管理和扩展应用程序成为可能，其实它们各自解决不同的问题，植根于非常不同的环境背景。
事实上，这三个广泛采用的工具链里没有一个是完全相同的。&lt;/p&gt;

&lt;p&gt;与其比较这几项快速发展的技术的重叠特性，不如让我们重新审视每个项目的原始使命、架构、以及他们如何互相补充与交互。&lt;/p&gt;

&lt;h3 id=&quot;从-docker-说起&quot;&gt;从 Docker 说起…&lt;/h3&gt;

&lt;p&gt;今天的 Docker 公司，起始于一家平台即服务（Platform-as-a-Service，PaaS）初创公司，叫做 dotCloud。
dotCloud 团队发现，为大量应用程序和大量客户去管理软件依赖和二进制文件需要许多工作量。
因此他们将 Linux cgroups 和命名空间（Namespace）的功能合并为一个独立的易用的包，以便应用程序能在任何基础设施上无差别的运行。
这个包就是 Docker 镜像，它提供以下功能：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;将应用程序和库封装进一个包&lt;/strong&gt;（Docker 镜像），应用程序可以一致地部署在多个环境；&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;提供类似 Git 的语义&lt;/strong&gt;，如 “docker push”, “docker commit”，让程序开发人员能轻松的采用新技术，并纳入其现有工作流；&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;将 Docker 镜像定义为不可变层&lt;/strong&gt;，支持不可变基础设施。发布的变动保存在单独的只读层，让重用镜像和追踪变更变得容易。层还能通过只传输变更而不是整个镜像，节省磁盘空间和网络带宽；&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;用不可变镜像启动 Docker 容器实例&lt;/strong&gt;，附带一个可写层来临时存储运行时更改，让应用程序快速部署和扩展变得容易。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Docker 越来越受欢迎，开发人员由在笔记本上运行容器，开始转为在生产环境运行容器。
这需要额外工具在多机之间协调容器，即容器编排。
有趣的是，运行于 Apache Mesos（下文详述）之上的 &lt;a href=&quot;https://mesosphere.github.io/marathon/&quot;&gt;Marathon&lt;/a&gt; 是支持 Docker 镜像（2014年6月）的首批容器编排工具之一。
那一年，Docker 的创始人兼 CTO Solomon Hykes 称赞 Mesos 为“&lt;a href=&quot;https://www.google.com/url?q=https://www.youtube.com/watch?v=sGWQ8WiGN8Y&amp;amp;feature=youtu.be&amp;amp;t=35m10s&amp;amp;sa=D&amp;amp;ust=1500923856666000&amp;amp;usg=AFQjCNFLtW96ZWnOUGFPX_XUuVOPdWrd_w&quot;&gt;生产集群的黄金标准&lt;/a&gt;”。
不久，除运行于 Mesos 之上的 Marathon，还出现了许多容器编排技术：&lt;a href=&quot;https://www.nomadproject.io/&quot;&gt;Nomad&lt;/a&gt;， &lt;a href=&quot;http://kubernetes.io/&quot;&gt;Kubernetes&lt;/a&gt;，毫不意外，还有 Docker Swarm（&lt;a href=&quot;https://blog.docker.com/2016/06/docker-1-12-built-in-orchestration/&quot;&gt;现在是 Docker Engine 的一部分&lt;/a&gt;）。&lt;/p&gt;

&lt;p&gt;随着 Docker 对开源文件格式进行商业化，该公司还开始引入工具来补充核心的 Docker 文件格式和运行引擎，包括：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Docker hub 用于 Docker 镜像公共存储；&lt;/li&gt;
  &lt;li&gt;Docker registry 用于内部存储；&lt;/li&gt;
  &lt;li&gt;Docker cloud，用于构建和运行容器对托管服务；&lt;/li&gt;
  &lt;li&gt;Docker datacenter 作为商业产品包含众多 Docker 技术。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://mesosphere.com/wp-content/uploads/2017/07/docker-host.png&quot; alt=&quot;Docker&quot; /&gt; &lt;br /&gt;
&lt;em&gt;来源: www.docker.com.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Docker 将软件及其依赖封装进一个软件包中，这一有洞察力的方式改变了软件行业规则；正如 mp3 帮助重塑了音乐行业一样。
Docker 文件格式成为行业标准，主要的容器技术厂商（包括 Docker、Google、Pivotal、Mesosphere 等）成立了 &lt;a href=&quot;https://www.cncf.io/&quot;&gt;Cloud Native Computing Foundation (CNCF)&lt;/a&gt; 和 &lt;a href=&quot;https://www.opencontainers.org/&quot;&gt;Open Container Initiative (OCI)&lt;/a&gt;。
今天，CNCF 和 OCI 旨在确保容器技术之间的互操作性和标准接口，并确保使用任何工具构建的 Docker 容器可以运行在任何运行环境和基础架构上。&lt;/p&gt;

&lt;h3 id=&quot;步入-kubernetes&quot;&gt;步入 Kubernetes&lt;/h3&gt;

&lt;p&gt;Google 一早就意识到 Docker 镜像文件的的潜力，并探索在 Google 的云平台上像服务一样交付容器编排。
Google 虽然在容器上有深厚的经验（他们在 Linux 中引入了 cgroups）, 但是在他们的基础架构上，内部容器和像 Borg 这样的分布式计算工具是紧密绑定在一起的。
因此，Google 没有使用任何已经存在系统的代码，而是重新设计了 Kubernetes 对 Docker 容器进行编排。
带着下面的目标和考虑，在 2015 年 2 月 kubernetes 发布了。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;辅助应用开放者&lt;/strong&gt;利用强大的 Docker 容器编排工具，不再需要和底层基础架构进行交互。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;提供标准的部署接口&lt;/strong&gt;和元语，以获得一致的应用部署的体验和跨云的 API。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;建立一个模块化的 API 核心&lt;/strong&gt;，允许厂商以 Kubernetes 技术为核心进行系统集成。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;2016 年 3 月，Google 向 CNCF &lt;a href=&quot;https://www.linuxfoundation.org/news-media/announcements/2016/03/cloud-native-computing-foundation-accepts-kubernetes-first-hosted-0&quot;&gt;捐赠了 Kubernetes&lt;/a&gt;，直到今天仍然保持着在这个项目的贡献者中首位的位置（其后是红帽，CoreOS 等）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://mesosphere.com/wp-content/uploads/2017/07/kubernetes-architecture.png&quot; alt=&quot;Kubernetes&quot; /&gt; &lt;br /&gt;
&lt;em&gt;来源: wikipedia&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;应用开发者对 Kubernetes 产生了很大的兴趣，因为 Kubernetes 降低了他们对基础架构和运维团队的依赖。
厂商也喜欢 Kubernetes, 因为它提供了一种简单的方式去拥抱容器，并且为运行自有的 Kubernetes 部署的运营挑战提供了商业化的解决方案（这是很有价值的事情）。
另外值得注意的是，Kubernetes 在 CNCF 的框架下开源，相对的是 Docker Swarm，虽然它也是开源的，但是实际上是被 Docker 公司牢牢控制。&lt;/p&gt;

&lt;p&gt;Kubernetes 的核心能力是给应用开发者提供强大的工具，编排无状态的 Docker 容器。
虽然已经有了多个提议，希望扩大这个项目的范围（比如数据分析和有状态的数据服务），这些提议仍然处于非常早期的阶段，能不能成功我们还需要保持观望。&lt;/p&gt;

&lt;h3 id=&quot;apache-mesos&quot;&gt;Apache Mesos&lt;/h3&gt;

&lt;p&gt;Apache Mesos是加州大学伯克利分校为了研发新一代集群管理器而发起的项目，它借鉴了 &lt;a href=&quot;https://research.google.com/pubs/pub43438.html&quot;&gt;Google Borg&lt;/a&gt; 系统和 &lt;a href=&quot;https://www.youtube.com/watch?v=C_WuUgTqgOc&quot;&gt;Facebook’s Tupperware&lt;/a&gt; 系统中大规模、分布式计算架构的相关经验，并把它应用到了mesos上。
当时Borg和Tupperware还是一个和基础设施紧密绑定，架构庞大，并且技术闭源的系统，而Mesos引入了一种开源的模块化架构，这种架构和底层的基础设施是完全独立开的。
为了使基础架构能够动态灵活扩展，&lt;a href=&quot;https://youtu.be/F1-UEIG7u5g&quot;&gt;Twitter&lt;/a&gt;, &lt;a href=&quot;http://www.businessinsider.com/apple-siri-uses-apache-mesos-2015-8&quot;&gt;Apple(Siri)&lt;/a&gt;, &lt;a href=&quot;https://engineeringblog.yelp.com/2015/11/introducing-paasta-an-open-platform-as-a-service.html&quot;&gt;Yelp&lt;/a&gt;, &lt;a href=&quot;http://highscalability.com/blog/2016/9/28/how-uber-manages-a-million-writes-per-second-using-mesos-and.html&quot;&gt;Uber&lt;/a&gt;, &lt;a href=&quot;http://highscalability.com/blog/2016/9/28/how-uber-manages-a-million-writes-per-second-using-mesos-and.html&quot;&gt;Netflix&lt;/a&gt; 还有很多高科技公司很快就把mesos应用到微服务，大数据计算，实时分析等业务上。&lt;/p&gt;

&lt;p&gt;Mesos作为一个集群资源管理器，它解决了以下一系列的难题和挑战：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;为了简化资源分配&lt;/strong&gt;，mesos将整个数据中心资源抽象为一个资源池，同时为私有云和公有云提供了一致的应用和操作体验；&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;为了提高资源利用率，减少成本&lt;/strong&gt;，mesos在同一基础架构上协调分配不同类型的工作任务，如数据分析，无状态微服务，分布式数据服务和传统应用程序;&lt;/li&gt;
  &lt;li&gt;使应用服务的相关任务（如部署，自我修复，扩展和升级）自动化，并且保证自动化流程高可用；&lt;/li&gt;
  &lt;li&gt;提供了有效的扩展性来运行新的应用程序而无需修改群集管理器和运行在它上面的的已有应用程序；&lt;/li&gt;
  &lt;li&gt;灵活的的扩展应用程序和底层基础架构，可以从几个节点扩展到数十个，甚至上万个节点。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Mesos具有一种独特的能力，它可以独自管理不同类型的工作任务，包括传统应用程序，如Java，无状态的Docker微服务，批处理作业，实时分析服务和有状态的分布式数据服务。
Mesos之所以能支持多种类型的工作任务，与它的两级架构设计密切相关，这种架构可以使应用在有感知的情况下完成资源调度。
这种调度方法是通过将应用程序特定的操作逻辑封装在“Mesos框架”（类似于操作中的运行手册）中来实现的。
然后，资源管理器Mesos Master在保持隔离的同时会把框架基础架构的这部分资源共享出来。
这种方法允许每个工作任务都有自己的专门调度器，这个调度器清楚其如何部署，扩展和升级等特定操作需求。
应用程序的调度器也是独立开发，管理和更新的，这样的设计使得Mesos具有高度的可扩展性，支持新的工作任务，或许将来会增加更多的功能特性。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://mesosphere.com/wp-content/uploads/2017/07/mesos-two-level-scheduler.png&quot; alt=&quot;Mesos two-level scheduler&quot; /&gt;&lt;/p&gt;

&lt;p&gt;以团队内部如何管理服务升级为例：
无状态的应用可以从&lt;a href=&quot;https://martinfowler.com/bliki/BlueGreenDeployment.html&quot;&gt;“blue/green”&lt;/a&gt;部署方法中获益；当旧的应用程序还运行着的时候，一个新版本完全运行起来时，流量会在旧程序销毁时完全切换到新版本的应用中。
但升级数据型工作任务时（如HDFS， Cassandra），每次要先拿掉一个节点，保留一份本地数据卷以避免数据丢失，按照顺序逐个升级下线的节点，同时要在每个节点升级前后执行指定的检测命令。
这些升级步骤都是和应用程序或服务相关联的，甚至和特定版本相关。
这使得使用常规容器编排管理这些数据服务变得异常困难。&lt;/p&gt;

&lt;p&gt;Mesos的这种保持每个工作任务以它自己的方式来管理资源调度的特性，使得许多公司将Mesos作为一个统一的平台，将微服务和数据服务同时运行在上面。
有一个类似的数据密集型架构可以参考，&lt;a href=&quot;https://mesosphere.com/blog/2017/06/21/smack-stack-new-lamp-stack/&quot;&gt;“SMACK stack”&lt;/a&gt;,即Spark,Mesos,Akka,Cassandra,Kafka 技术栈。&lt;/p&gt;

&lt;h3 id=&quot;几点声明&quot;&gt;几点声明&lt;/h3&gt;

&lt;p&gt;请注意，我们在描述 Apache Mesos 时并未提及任何有关容器编排的内容。
那么为什么人们总是自动把容器编排和 Mesos 关联起来呢？
容器编排是可以在mesos模块化结构上运行任务的一个例子，其功能已经由运行在Mesos之上的专门编排“框架”实现，该“框架”名为 Marathon。Marathon 最初在 cgroup 容器中管理应用程序包（例如JAR包、TAR包及ZIP文件），也是第一个支持 docker 容器的容器编排工具（2014年实现该功能）。&lt;/p&gt;

&lt;p&gt;所以当人们用 Docker 和 Kubernetes 同 Mesos 比较时，实际上比较的是 Kubernets、Docker Swarm 和运行在 Mesos 上的 Marathon。&lt;/p&gt;

&lt;p&gt;为什么这点很重要？
因为坦率的讲，Mesos并不关心谁在它上面运行。
Mesos可以弹性为 JAVA 应用服务器、Docker 容器编排、Jenkins CI 作业、Apache Spark分析、Apache Kafka流等共享基础设施提供集群服务。
Mesos 上甚至可以运行 Kubernetes 或其他容器编排工具，尽管一体化集成尚未实现。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://mesosphere.com/wp-content/uploads/2017/07/mesos-workloads.png&quot; alt=&quot;Mesos Workloads&quot; /&gt; &lt;br /&gt;
&lt;em&gt;来源：Apache Mesos Survey 2016&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;另一个值得考虑 Mesos 的因素（也是吸引大量企业架构师的原因）是其运行关键性任务的成熟度。
Mesos已经在大量生产环境（成千上万台服务器）中运行超过7年，这就是为什么说相对于市场上的其他容器技术，Mesos已经应用于大量生产环境，拥有可靠的规模。&lt;/p&gt;

&lt;h3 id=&quot;这些都意味着什么&quot;&gt;这些都意味着什么？&lt;/h3&gt;

&lt;p&gt;综上所述，所有这三种技术都与 Docker 容器有关，并允许你使用容器编排实现应用程序可移植和扩展。
那么它们之间如何选择呢？
归结为：为工作任务选择合适的工具（甚至可能是不同的工作选择不同的工具）。
如果你是程序开发人员，正在探寻现代化的方式来构建和打包应用程序，或加速微服务计划，Docker 容器格式和开发工具是最好的途径。&lt;/p&gt;

&lt;p&gt;如果你是一个开发／运维团队，希望构建专用于 Docker 容器编排的系统，并愿意着手将你的解决方案与底层基础设施（或依赖 Google Container Engine、Azure Container Service 之类的公共云基础设施）进行整合，Kubernetes 是可考虑的不错的技术选择。&lt;/p&gt;

&lt;p&gt;如果你希望建立一个可靠的平台，允许多项关键工作任务如 Docker 容器、传统应用程序（例如 Java）和分布式数据服务（例如 Spark、Kafka、Cassandra、Elastic），并希望所有这些可以跨云服务商和／或数据中心移植，那么 Mesos（或 Mesosphere DC/OS）适合你。&lt;/p&gt;

&lt;p&gt;无论你作何选择，都将拥有一套可以更有效利用服务器资源、简化应用程序移植、并提高开发人员敏捷性的工具。
绝对没错。&lt;/p&gt;</content><author><name></name></author><category term="Docker" /><category term="Kubernetes" /><category term="Mesos" /><summary type="html">有无数的文章、讨论和社交网络上的交流在比较 Docker、Kubernetes 和 Mesos。 如果只听取部分信息，你会以为这三个开源项目正在为容器世界的霸权而决战。 你也可能相信选择其一几乎是一个宗教选择；真正的信徒维护他们的信仰，烧死胆敢考虑其它替代品的异端者。</summary></entry><entry><title type="html">rabbitmq vs kafka</title><link href="http://localhost:4000/rabbitmq-vs-kafka/" rel="alternate" type="text/html" title="rabbitmq vs kafka" /><published>2017-07-20T00:00:00+08:00</published><updated>2017-07-20T00:00:00+08:00</updated><id>http://localhost:4000/rabbitmq-vs-kafka</id><content type="html" xml:base="http://localhost:4000/rabbitmq-vs-kafka/">&lt;p&gt;有人说 rabbitmq 做队列好
有人说 kafka 做队列好&lt;/p&gt;

&lt;!--excerpt--&gt;
&lt;p&gt;###Kafka VS Rabbitmq&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Message queue is a well known architectural pattern that provide an asynchronous communication protocol. It means that sender and receiver of the message are completely detached, they do not need to interact with a queueing system at the same time.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;####MQ makes message queues (or message brokers) very useful for:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;decoupling of services&lt;/li&gt;
  &lt;li&gt;painless scaling&lt;/li&gt;
  &lt;li&gt;backpressure management&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;==============&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Kafka&lt;/code&gt;: - high-throughput distributed messaging system&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;RabbitMQ&lt;/code&gt; - reliable message broker (AMQP based)&lt;/p&gt;

&lt;p&gt;| Feature | RabbitMq | Kafka |
| :—         |     :—:      |          —: |
| ` what is it&lt;code class=&quot;highlighter-rouge&quot;&gt;   |  RabbitMQ is a solid, mature, general purpose message broker that supports several standardized protocols such as AMQP      | Apache Kafka is a message bus optimized for high-ingress data streams and replay   |
| &lt;/code&gt; Primary use&lt;code class=&quot;highlighter-rouge&quot;&gt;   |  High-throughput and reliable background jobs, communication and integration within, and between applications.      | Build applications that process and re-process streamed data on disk    |
| &lt;/code&gt; routing approach&lt;code class=&quot;highlighter-rouge&quot;&gt;   |  rich: topic -&amp;gt; direct,topic,headers,fanout      | simple: topic -&amp;gt; Consumer Group    |
|&lt;/code&gt; throuput / 1 pc&lt;code class=&quot;highlighter-rouge&quot;&gt;     | 20000 msg/sec      | 100000 msg/sec     |
| &lt;/code&gt;client SDK support&lt;code class=&quot;highlighter-rouge&quot;&gt;    | multiple languages      | multiple languages      |
| &lt;/code&gt;message delay&lt;code class=&quot;highlighter-rouge&quot;&gt;    |  μs      | ms      |
| &lt;/code&gt;federated queues&lt;code class=&quot;highlighter-rouge&quot;&gt;    |  can be use to migrate cluster      | kafka mirror-maker have same function     |
| &lt;/code&gt;availability and failover&lt;code class=&quot;highlighter-rouge&quot;&gt;    |    HA with mirror queue    | HA with replica      |
| &lt;/code&gt;message lost&lt;code class=&quot;highlighter-rouge&quot;&gt;   |   under control    | Under control after 0.11      |
| &lt;/code&gt;message duplicated&lt;code class=&quot;highlighter-rouge&quot;&gt;    |    under control    |1） not avoidable prior to 0.11 because of at lease once semantics, 0.11 introduced exactly once semantics 2）kafka stream     |
| &lt;/code&gt;Order Message&lt;code class=&quot;highlighter-rouge&quot;&gt;    |  Exclusive Consumer or Exclusive Queues can ensure ordering      | Ensure ordering of messages within a partition     |
| &lt;/code&gt;message priority&lt;code class=&quot;highlighter-rouge&quot;&gt;    |  supported      | not supported      |
| &lt;/code&gt;message track&lt;code class=&quot;highlighter-rouge&quot;&gt;    |  supported      | not supported      |
| &lt;/code&gt;Management and Operation Tools&lt;code class=&quot;highlighter-rouge&quot;&gt;    |  supported as plugin     | not supported (need to install 3rd party tool e.g. kafka-manager)    |
| &lt;/code&gt;scalibility`    | Depends on the consumer,  you can add many consumers as you want, and there is no limit in theory      | Depends on the partition number, eg: 500 partitions, only 500 threads can consume from the topic, not meaning to add more threads.      |&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Conclusion is simple:&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Kafka is good for high throuput scenario&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;RabbitMQ is good for reliable and flexible topic routing scenario ((surely, rabbitmq can also handle large throuput, but it needs more machines compred with kafka.)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;###Our rabbitmq use case:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Notification center service&lt;/code&gt;’&lt;/p&gt;

    &lt;p&gt;Once message arrives, will notify client&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Why Rabbitmq in Notification center&lt;/code&gt;&lt;/p&gt;

    &lt;p&gt;Rabbitmq is mature, and developer is veryfamaliar with python + rabbitmq, and rabbitmq is reliable.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;This function can be implemented with kafka as well, but developer thinks rabbitmq is much easier, and the exchange routing strategy is more flexsible.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;other-rabbitmq-use-case&quot;&gt;Other rabbitmq use case&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;User order priority in shopping mall&lt;/code&gt;&lt;/p&gt;

    &lt;p&gt;e.g.: pub A -&amp;gt; Rabbitmq -&amp;gt; consumer B&lt;/p&gt;

    &lt;p&gt;consumer B get all the orders from rabbitmq to handle, B can take priority of the order from VIP customer, this makes sense.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Note: There are only two hard problems in distributed systems&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;Exactly-once delivery&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;Guaranteed order of messages&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;####Reference:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;rabbitmq-hits-one-million-messages-per-second-on-google-compute-engine&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;https://content.pivotal.io/blog/rabbitmq-hits-one-million-messages-per-second-on-google-compute-engine&lt;/p&gt;</content><author><name></name></author><category term="rabbitmq" /><category term="kafka" /><summary type="html">有人说 rabbitmq 做队列好 有人说 kafka 做队列好</summary></entry></feed>